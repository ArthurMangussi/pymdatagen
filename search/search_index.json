{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"mdatagen: A Python Library For the Artificial Generation of Missing Data","text":""},{"location":"#overview","title":"Overview","text":"<p>This package has been developed to address a gap in machine learning research, specifically the artificial generation of missing data. Santos et al. (2019) provided a survey that presents various strategies for both univariate and multivariate scenarios, but the Python community still needs implementations of these strategies. Our Python library missing-data-generator (mdatagen) puts forward a comprehensive set of implementations of missing data mechanisms, covering Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR), allowing users to simulate several real-world scenarios comprising absent observations. The library is designed for easy integration with existing Python-based data analysis workflows, including well-established modules such as scikit-learn, and popular libraries for missing data visualization, such as missingno, enhancing its accessibility and usability for researchers.</p> <p>This Python package is a collaboration between researchers at the Aeronautics Institute of Technologies (Brazil) and the University of Coimbra (Portugal).</p>"},{"location":"#user-guide","title":"User Guide","text":"<p>Please refer to the univariate docs or multivariate docs for more implementatios details.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install the package, please use the <code>pip</code> installation as follows:</p> <pre><code>pip install mdatagen\n</code></pre>"},{"location":"#api-usage","title":"API Usage","text":"<p>API usage is described in each of the following sections</p> <ul> <li>MCAR univariate example</li> <li>MNAR univariate example</li> <li>MAR univariate example</li> <li>MNAR Multivariate Examples</li> <li>Novel MNAR Multivariate mechanism</li> <li>Evaluation of Imputation Quality</li> <li>Visualization Plots</li> <li>Complete Pipeline Example</li> </ul>"},{"location":"#code-examples","title":"Code examples","text":"<p>Here, we provide a basic usage for MAR mechanism in both univariate and multivariate scenarios to getting started. Also, we illustrate how to use the Histogram plot and evaluate the imputation quality. </p>"},{"location":"#mar-univariate","title":"MAR univariate","text":"<pre><code>import pandas as pd\nfrom sklearn.datasets import load_iris\n\nfrom mdatagen.univariate.uMAR import uMAR\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, \n                      columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target      # Label values\n\ngenerator = uMAR(X=X, \n                  y=y, \n                  missing_rate=50, \n                  x_miss='sepal length (cm)',\n                  x_obs = 'petal lenght (cm)')\n\n# Generate the missing data under MAR mechanism univariate\ngenerate_data = generator.rank()\nprint(generate_data.isna().sum())\n</code></pre>"},{"location":"#mar-multivariate","title":"MAR multivariate","text":"<pre><code>import pandas as pd\nfrom sklearn.datasets import load_iris\n\nfrom mdatagen.multivariate.mMAR import mMAR\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, \n                      columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target      # Label values\n\ngenerator = mMAR(X=X, \n                  y=y)\n\n# Generate the missing data under MAR mechanism multivariate\ngenerate_data = generator.correlated(missing_rate=25)\nprint(generate_data.isna().sum())\n</code></pre>"},{"location":"#histogram-plot","title":"Histogram plot","text":"<pre><code>import pandas as pd\nfrom sklearn.datasets import load_iris\n\nfrom mdatagen.univariate.uMCAR import uMCAR\nfrom mdatagen.plots.plot import PlotMissingData\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, \n                        columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target      # Label values\n\n# Create a instance with missing rate \n# equal to 25% in dataset under MCAR mechanism\ngenerator = uMCAR(X=X, \n                  y=y, \n                  missing_rate=25, \n                  x_miss='petal length (cm)')\n\n# Generate the missing data under MNAR mechanism\ngenerate_data = generator.random()\n\n\nmiss_plot = PlotMissingData(data_missing=generate_data,\n                            data_original=X\n                            )\nmiss_plot.visualize_miss(\"histogram\",\n                         col_missing=\"petal length (cm)\",\n                         save=True,\n                         path_save_fig = \"MCAR_iris.png\")\n</code></pre>"},{"location":"#imputation-quality-evaluation-mean-squared-error-mse","title":"Imputation Quality Evaluation: Mean Squared Error (MSE)","text":"<pre><code>import pandas as pd\nfrom sklearn.datasets import load_iris\n\nfrom mdatagen.univariate.uMCAR import uMCAR\nfrom mdatagen.metrics import EvaluateImputation\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, \n                        columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target      # Label values\n\n# Create a instance with missing rate \n# equal to 25% in dataset under MCAR mechanism\ngenerator = uMCAR(X=X, \n                  y=y, \n                  missing_rate=25, \n                  x_miss='petal length (cm)')\n\n# Generate the missing data under MNAR mechanism\ngenerate_data = generator.random()\n\n# Calculate the metric: MSE\nfill_zero = generate_data.drop(\"target\",axis=1).fillna(0)\neval_metric = EvaluateImputation(\n            data_imputed=fill_zero,\n            data_original=X,\n            metric=\"mean_squared_error\")\nprint(eval_metric.show())\n</code></pre>"},{"location":"#contribuitions","title":"Contribuitions","text":"<p>Contributions are welcome! Feel free to open issues, submit pull requests, or provide feedback.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use mdatagen in your research, please cite the package as an independent software tool. Additionally, if your research benefits from the concepts or methodologies discussed in the survey by Santos et al. (2019), we encourage citing their work as well.</p>"},{"location":"#citation-for-the-mdatagen-package","title":"Citation for the mdatagen package:","text":"<p>The mdatagen package is an independent Python library designed to generate artificial missing data. It does not reproduce or extend the implementation of any previous work, but it is related to ideas explored in Santos et al. (2019). Please cite the package as follows:</p> <p>Bibtex entry: <pre><code>@article{MANGUSSI2025,\ntitle = {mdatagen: A python library for the artificial generation of missing data},\njournal = {Neurocomputing},\nvolume = {625},\npages = {129478},\nyear = {2025},\nissn = {0925-2312},\ndoi = {https://doi.org/10.1016/j.neucom.2025.129478},\nurl = {https://www.sciencedirect.com/science/article/pii/S092523122500150X},\nauthor = {Arthur Dantas Mangussi and Miriam Seoane Santos and Filipe Loyola Lopes and Ricardo Cardoso Pereira and Ana Carolina Lorena and Pedro Henriques Abreu}\n}\n</code></pre></p>"},{"location":"#citation-for-the-survey-by-santos-et-al-2019","title":"Citation for the survey by Santos et al. (2019):","text":"<p>If your work references concepts or methodologies discussed in the survey by Santos et al. (2019), please also cite their paper:</p> <p>Bibtex entry: <pre><code>@ARTICLE{Santos2019,\n  author={Santos, Miriam Seoane and Pereira, Ricardo Cardoso and Costa, Adriana Fonseca and Soares, Jastin Pompeu and Santos, Jo\u00e3o and Abreu, Pedro Henriques},\n  journal={IEEE Access}, \n  title={Generating Synthetic Missing Data: A Review by Missing Mechanism}, \n  year={2019},\n  volume={7},\n  number={},\n  pages={11651-11667},\n  doi={10.1109/ACCESS.2019.2891360}}\n</code></pre></p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>The authors gratefully acknowledge the Brazilian funding agencies FAPESP (Funda\u00e7\u00e3o Amparo \u00e0 Pesquisa do Estado de S\u00e3o Paulo) under grants 2021/06870-3, 2022/10553-6, and 2023/13688-2. Moreover, this research was supported in part by the Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoalde N\u00edvel Superior - Brasil (CAPES) - Finance\u00a0Code\u00a0001, and Portuguese Recovery and Resilience Plan (PRR) through project C645008882-00000055 Center for Responsable AI.</p>"},{"location":"compatibility_with_tensorflow/","title":"Compatibility with tensorflow","text":"<p>This jupyter notebook provides an example of generate artificial missing data under MNAR multivariate mechanisms using a Tensorflow imputation method named Partial Multiple Imputation With Variational Autoencoders (PMIVAE). In the original article the authors proposed PMIVAE under MNAR mechanism.</p> <p>Reference:  Pereira RC, Abreu PH, Rodrigues PP. Partial Multiple Imputation With Variational Autoencoders: Tackling Not at Randomness in Healthcare Data. IEEE J Biomed Health Inform. 2022 Aug;26(8):4218-4227. doi: 10.1109/JBHI.2022.3172656. Epub 2022 Aug 11. PMID: 35511840.</p> In\u00a0[1]: Copied! <pre># Import the libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\n\nfrom mdatagen.multivariate.mMNAR import mMNAR\n\n# Load the data\nwiscosin = load_breast_cancer()\nwiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names) # Dataset used in PMIVAE paper\n\nX = wiscosin_df.copy()   # Features\ny = wiscosin.target    # Label values\n</pre> # Import the libraries import pandas as pd import numpy as np from sklearn.datasets import load_breast_cancer  from mdatagen.multivariate.mMNAR import mMNAR  # Load the data wiscosin = load_breast_cancer() wiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names) # Dataset used in PMIVAE paper  X = wiscosin_df.copy()   # Features y = wiscosin.target    # Label values In\u00a0[2]: Copied! <pre># Create a instance for MNAR mechanism\ngenerator = mMNAR(X=X, \n                  y=y,\n                  n_xmiss=X.shape[1], # all features will receive the missing values\n                  threshold = 0) # highest values\n\n# Generate the missing data under MNAR mechanism up to 20% missing rate\ngenerate_data = generator.random(missing_rate=20, \n                                 deterministic=True) # Missingness based on own values\n</pre> # Create a instance for MNAR mechanism generator = mMNAR(X=X,                    y=y,                   n_xmiss=X.shape[1], # all features will receive the missing values                   threshold = 0) # highest values  # Generate the missing data under MNAR mechanism up to 20% missing rate generate_data = generator.random(missing_rate=20,                                   deterministic=True) # Missingness based on own values In\u00a0[3]: Copied! <pre>qtd_miss = sum(generate_data.isna().sum())\ndata_dimension = generate_data.shape[0]*generate_data.shape[1]\nprint(f\"Global Missing rate = {round(qtd_miss/(data_dimension),4)*100}%\")\n</pre> qtd_miss = sum(generate_data.isna().sum()) data_dimension = generate_data.shape[0]*generate_data.shape[1] print(f\"Global Missing rate = {round(qtd_miss/(data_dimension),4)*100}%\") <pre>Global Missing rate = 19.39%\n</pre> <p>Once the missingness is introduced, we will perform the imputation process using PMIVAE, which was designed with a TensorFlow architecture. To use this autoencoder, you have to following these steps: </p> <ol> <li>Go to GitHub repository: https://github.com/ricardodcpereira/PMIVAE</li> <li>Clone the repository</li> <li>Use the following code</li> </ol> In\u00a0[4]: Copied! <pre># import sys\n# sys.path.append(\"path/to/pmivae/folder\")\n\nfrom pmivae import ConfigVAE, PMIVAE\n\noriginal_shape = X.shape\n\ny_train = generate_data[\"target\"]\nX_train = generate_data.drop(columns=\"target\")\n\nvae_config = ConfigVAE()\nvae_config.verbose = 0\nvae_config.batch_size = 128\nvae_config.validation_split=0.2\nvae_config.input_shape = (original_shape[1],)\nvae_config.epochs = 200\n\npmivae_model = PMIVAE(vae_config, num_samples=200)\npmivae_model_trained = pmivae_model.fit(X=X_train.values,\n                                        y=y_train)\n</pre> # import sys # sys.path.append(\"path/to/pmivae/folder\")  from pmivae import ConfigVAE, PMIVAE  original_shape = X.shape  y_train = generate_data[\"target\"] X_train = generate_data.drop(columns=\"target\")  vae_config = ConfigVAE() vae_config.verbose = 0 vae_config.batch_size = 128 vae_config.validation_split=0.2 vae_config.input_shape = (original_shape[1],) vae_config.epochs = 200  pmivae_model = PMIVAE(vae_config, num_samples=200) pmivae_model_trained = pmivae_model.fit(X=X_train.values,                                         y=y_train) <pre>WARNING:tensorflow:From D:\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nWARNING:tensorflow:From D:\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n\nWARNING:tensorflow:From D:\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n\nWARNING:tensorflow:From D:\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From D:\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n\n</pre> In\u00a0[5]: Copied! <pre>data_imputed = pmivae_model_trained.transform(X_train.values)\n</pre> data_imputed = pmivae_model_trained.transform(X_train.values) <pre>18/18 [==============================] - 0s 1ms/step\n18/18 [==============================] - 0s 1ms/step\n</pre> In\u00a0[6]: Copied! <pre>pd.DataFrame(data_imputed, columns=X.columns)\n</pre> pd.DataFrame(data_imputed, columns=X.columns) Out[6]: mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension ... worst radius worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension 0 0.973514 0.979600 0.967979 0.996791 0.118444 0.115564 0.136443 0.086983 0.198542 0.092786 ... 0.973581 0.986063 0.971022 0.978695 0.140569 0.305402 0.345007 0.138460 0.319906 0.126009 1 0.988317 0.991404 0.984745 0.999256 0.081741 0.083662 0.095840 0.055880 0.159507 0.060012 ... 0.988441 0.995054 0.987395 0.989881 0.104522 0.282253 0.331156 0.096495 0.288463 0.084480 2 0.986490 0.989981 0.982597 0.999037 0.087365 0.088643 0.102123 0.060483 0.165915 0.064881 ... 0.986614 0.994058 0.985386 0.988453 0.110230 0.286262 0.333581 0.102970 0.293879 0.090776 3 0.787963 0.713743 0.713717 0.752805 0.316942 0.280540 0.263756 0.335186 0.228419 0.318733 ... 0.738740 0.891356 0.813159 0.749234 0.346905 0.405063 0.385105 0.177233 0.317348 0.204692 4 0.972593 0.978849 0.966973 0.996588 0.120267 0.117116 0.138436 0.088589 0.200334 0.094471 ... 0.972654 0.985445 0.969999 0.978022 0.142294 0.306400 0.345596 0.140526 0.321269 0.128094 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 564 0.977750 0.983033 0.972652 0.997653 0.109540 0.107942 0.126675 0.079217 0.189613 0.084629 ... 0.977845 0.988828 0.975726 0.981823 0.132060 0.300353 0.342016 0.128342 0.313016 0.115850 565 0.962130 0.970212 0.955752 0.993880 0.138852 0.132813 0.158650 0.105255 0.217998 0.111918 ... 0.962094 0.978037 0.958338 0.970472 0.159614 0.315991 0.351230 0.161502 0.334401 0.149440 566 0.974883 0.980714 0.969481 0.997083 0.115663 0.113190 0.133397 0.084544 0.195785 0.090226 ... 0.974960 0.986971 0.972544 0.979702 0.137925 0.303857 0.344093 0.135304 0.317795 0.122832 567 0.942844 0.953886 0.935814 0.987023 0.166371 0.155698 0.188238 0.130841 0.242446 0.138578 ... 0.942562 0.962844 0.936770 0.956927 0.184477 0.328620 0.358572 0.192262 0.351756 0.181266 568 0.985718 0.989376 0.981698 0.998937 0.089608 0.090619 0.104622 0.062336 0.168422 0.066839 ... 0.985841 0.993626 0.984537 0.987855 0.112485 0.287805 0.334512 0.105549 0.295968 0.093296 <p>569 rows \u00d7 30 columns</p> <p>Therefore, in this Jupyter Notebook, we have demonstrated that our mdatagen package is compatible with TensorFlow architecture by using the PMIVAE imputation algorithm to address missing data issues. It is important to note that mdatagen primarily focuses on the Data Amputation step (i.e., scikit-learn algorithms, TensorFlow, and/or algorithms based on other frameworks are compatible, as they are part of the data imputation step)</p>"},{"location":"complete_pipeline_example/","title":"Complete Pipeline Example","text":"<p>This Jupyter Notebook provide a complete example of classical experimental setup for Missing Data studies. The main four steps are (Santos et al. (2019)):</p> <ul> <li>Data Collection: We used the Breast Cancer Wiscosin from Scikit-learn, which is complete (i.e., without missing values)</li> <li>Missing Data Generation: We selected to generate artificial missing data under MNAR mechanism</li> <li>Imputation: We performed the imputation by k-Nearst Neighbors (kNN)</li> <li>Evaluation: We evaluated the imputation quality with Mean Squared Error (MSE)</li> </ul> In\u00a0[1]: Copied! <pre>## View the version installed\nimport mdatagen\n\nmdatagen.__version__\n</pre> ## View the version installed import mdatagen  mdatagen.__version__ Out[1]: <pre>'0.1.71'</pre> In\u00a0[2]: Copied! <pre>import pandas as pd\nimport numpy as np \nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.impute import KNNImputer\n\nfrom mdatagen.multivariate.mMNAR import mMNAR\nfrom mdatagen.metrics import EvaluateImputation\nfrom mdatagen.plots import PlotMissingData\n</pre> import pandas as pd import numpy as np  from sklearn.datasets import load_breast_cancer from sklearn.impute import KNNImputer  from mdatagen.multivariate.mMNAR import mMNAR from mdatagen.metrics import EvaluateImputation from mdatagen.plots import PlotMissingData In\u00a0[3]: Copied! <pre># Load the data\nwiscosin = load_breast_cancer()\nwiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names)\n\nX = wiscosin_df.copy()   # Features\ny = wiscosin.target    # Label values\n</pre> # Load the data wiscosin = load_breast_cancer() wiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names)  X = wiscosin_df.copy()   # Features y = wiscosin.target    # Label values In\u00a0[4]: Copied! <pre># Create a instance with missing rate equal to 20% in dataset under MNAR mechanism\ngenerator = mMNAR(X=X, y=y)\n\n# Generate the missing data under MNAR mechanism\ngenerate_MDdata = generator.random(missing_rate=20,\n                                   deterministic=True)\n</pre> # Create a instance with missing rate equal to 20% in dataset under MNAR mechanism generator = mMNAR(X=X, y=y)  # Generate the missing data under MNAR mechanism generate_MDdata = generator.random(missing_rate=20,                                    deterministic=True) In\u00a0[5]: Copied! <pre># Visualize the missingness \nmiss_plot = PlotMissingData(data_missing=generate_MDdata, \n                            data_original=wiscosin_df)\n\nmiss_plot.visualize_miss(\"normal\", save=False)\n</pre> # Visualize the missingness  miss_plot = PlotMissingData(data_missing=generate_MDdata,                              data_original=wiscosin_df)  miss_plot.visualize_miss(\"normal\", save=False) In\u00a0[17]: Copied! <pre># Initialize the kNN imputer with k=3\nimputer = KNNImputer(n_neighbors=3)\n\n# Training the Imputer\nimputer.fit(generate_MDdata)\n\ncol = X.columns.to_list() # Columns names in result dataframe\ncol.append(\"target\")\n\ndf_imputed = pd.DataFrame(\n    imputer.transform(generate_MDdata), columns = pd.Index(col)\n)\n</pre> # Initialize the kNN imputer with k=3 imputer = KNNImputer(n_neighbors=3)  # Training the Imputer imputer.fit(generate_MDdata)  col = X.columns.to_list() # Columns names in result dataframe col.append(\"target\")  df_imputed = pd.DataFrame(     imputer.transform(generate_MDdata), columns = pd.Index(col) )  In\u00a0[18]: Copied! <pre>df_original = X.copy()\ndf_original[\"target\"] = y \n\nmaes = []\nfeatures = generate_MDdata.columns[\n    generate_MDdata.isna().any()\n].tolist()\n\nfor feature in features:\n    missing_id = generate_MDdata.columns.get_loc(feature)\n    linhas_nan = generate_MDdata.iloc[:, missing_id][\n        generate_MDdata.iloc[:, missing_id].isna()\n    ].index\n\n    eval_metric = EvaluateImputation(data_imputed=df_imputed.iloc[linhas_nan, missing_id],\n                                    data_original=df_original.iloc[linhas_nan, missing_id],\n                                    metric=\"mean_absolute_error\")\n    \n    mae = eval_metric.show()\n    maes.append(mae)\n\nprint(f\"Average MAE: {round(np.mean(maes),3)} +- {round(np.std(maes),3)}\")\n</pre> df_original = X.copy() df_original[\"target\"] = y   maes = [] features = generate_MDdata.columns[     generate_MDdata.isna().any() ].tolist()  for feature in features:     missing_id = generate_MDdata.columns.get_loc(feature)     linhas_nan = generate_MDdata.iloc[:, missing_id][         generate_MDdata.iloc[:, missing_id].isna()     ].index      eval_metric = EvaluateImputation(data_imputed=df_imputed.iloc[linhas_nan, missing_id],                                     data_original=df_original.iloc[linhas_nan, missing_id],                                     metric=\"mean_absolute_error\")          mae = eval_metric.show()     maes.append(mae)  print(f\"Average MAE: {round(np.mean(maes),3)} +- {round(np.std(maes),3)}\") <pre>Average MAE: 14.796 +- 47.568\n</pre>"},{"location":"complete_pipeline_example/#import-the-libraries","title":"Import the libraries\u00b6","text":""},{"location":"complete_pipeline_example/#step-1-data-collection","title":"Step 1: Data Collection\u00b6","text":""},{"location":"complete_pipeline_example/#step-2-missing-data-generation","title":"Step 2: Missing Data Generation\u00b6","text":""},{"location":"complete_pipeline_example/#step-3-imputation","title":"Step 3: Imputation\u00b6","text":""},{"location":"complete_pipeline_example/#step-4-evalutation","title":"Step 4: Evalutation\u00b6","text":"<p>Measuring the imputation quality, which is the direct evaluation, by Mean Absolute Error (MAE). Here, we calculated the average MAE for each column that has Missing Data.</p>"},{"location":"evaluation_imputation_quality/","title":"Evaluation of Imputation Quality","text":"<p>A basic example of generate artificial missing data with mdatagen library with the Iris dataset from scikit-learn. The feature petal length will receive the missing values under Missing Completly at Random (MCAR) mechanism. The simulated missing rate is 25%. The method to choose missing values is random. Our example fills the missing values with zero and evaluted the imputation quality with Mean Squared Error (MSE).</p> In\u00a0[1]: Copied! <pre># Import the libraries\nimport pandas as pd\nfrom sklearn.datasets import load_iris\n\nfrom mdatagen.univariate.uMCAR import uMCAR\nfrom mdatagen.metrics import EvaluateImputation\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target    # Label values\n\n# Create a instance with missing rate equal to 25% in dataset under MCAR mechanism\ngenerator = uMCAR(X=X, y=y, missing_rate=25, x_miss='petal length (cm)')\n\n# Generate the missing data under MNAR mechanism\ngenerate_data = generator.random()\n\neval_metric = EvaluateImputation(data_imputed=generate_data.drop(\"target\",axis=1).fillna(0),\n                                    data_original=X,\n                                    metric=\"mean_squared_error\")\nprint(\"MSE:\", round(eval_metric.show(),3))\n</pre> # Import the libraries import pandas as pd from sklearn.datasets import load_iris  from mdatagen.univariate.uMCAR import uMCAR from mdatagen.metrics import EvaluateImputation  # Load the data iris = load_iris() iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  X = iris_df.copy()   # Features y = iris.target    # Label values  # Create a instance with missing rate equal to 25% in dataset under MCAR mechanism generator = uMCAR(X=X, y=y, missing_rate=25, x_miss='petal length (cm)')  # Generate the missing data under MNAR mechanism generate_data = generator.random()  eval_metric = EvaluateImputation(data_imputed=generate_data.drop(\"target\",axis=1).fillna(0),                                     data_original=X,                                     metric=\"mean_squared_error\") print(\"MSE:\", round(eval_metric.show(),3)) <pre>MSE: 1.081\n</pre>"},{"location":"examples_plots/","title":"Visualization Plots","text":"<p>This Jupyter notebook provide some examples of how to use the Visualization module from mdatagen. The first step is get Iris dataset from Scikit-Learn. Afterward, we will generate missing values as following:</p> In\u00a0[31]: Copied! <pre># Get iris dataset and insert MV in 2 columns\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nimport numpy as np\nfrom typing import Optional\nfrom mdatagen.plots import PlotMissingData\n\ndef create_iris_missing(mrate, col_1:str, col_2:Optional[str]=None):\n    iris = load_iris()\n    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    #iris_df['target'] = iris.target\n\n    iris_miss = iris_df.copy()\n    num_missing = int(mrate * len(iris_miss))\n    missing_indices = np.random.choice(iris_miss.index, size=num_missing, replace=False)\n    iris_miss.loc[missing_indices, col_1] = np.nan\n\n    if col_2:\n        missing_indices = np.random.choice(iris_miss.index, size=num_missing, replace=False)\n        iris_miss.loc[missing_indices, col_2] = np.nan\n\n    return iris_df, iris_miss\n</pre> # Get iris dataset and insert MV in 2 columns import pandas as pd from sklearn.datasets import load_iris import numpy as np from typing import Optional from mdatagen.plots import PlotMissingData  def create_iris_missing(mrate, col_1:str, col_2:Optional[str]=None):     iris = load_iris()     iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)     #iris_df['target'] = iris.target      iris_miss = iris_df.copy()     num_missing = int(mrate * len(iris_miss))     missing_indices = np.random.choice(iris_miss.index, size=num_missing, replace=False)     iris_miss.loc[missing_indices, col_1] = np.nan      if col_2:         missing_indices = np.random.choice(iris_miss.index, size=num_missing, replace=False)         iris_miss.loc[missing_indices, col_2] = np.nan      return iris_df, iris_miss In\u00a0[32]: Copied! <pre>mr = 0.4\ncol_1 = \"petal length (cm)\"\ncol_2 = \"sepal width (cm)\"\ncols = (col_1, col_2)\niris_df, iris_miss = create_iris_missing(mr, col_1=\"petal length (cm)\")\n</pre> mr = 0.4 col_1 = \"petal length (cm)\" col_2 = \"sepal width (cm)\" cols = (col_1, col_2) iris_df, iris_miss = create_iris_missing(mr, col_1=\"petal length (cm)\") In\u00a0[4]: Copied! <pre>iris_df\n</pre> iris_df Out[4]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 ... ... ... ... ... 145 6.7 3.0 5.2 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 <p>150 rows \u00d7 4 columns</p> In\u00a0[5]: Copied! <pre>iris_miss\n</pre> iris_miss Out[5]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 NaN 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 NaN 0.2 ... ... ... ... ... 145 6.7 3.0 NaN 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 NaN 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 <p>150 rows \u00d7 4 columns</p> In\u00a0[\u00a0]: Copied! <pre>miss_plot = PlotMissingData(data_missing=iris_miss, data_original=iris_df)\n</pre> miss_plot = PlotMissingData(data_missing=iris_miss, data_original=iris_df) In\u00a0[7]: Copied! <pre>miss_plot.visualize_miss(\"normal\")\n</pre> miss_plot.visualize_miss(\"normal\") In\u00a0[8]: Copied! <pre>miss_plot.visualize_miss(\"bar\")\n</pre> miss_plot.visualize_miss(\"bar\") In\u00a0[9]: Copied! <pre>miss_plot.visualize_miss(\"dendrogram\")\n</pre> miss_plot.visualize_miss(\"dendrogram\") In\u00a0[10]: Copied! <pre>miss_plot.visualize_miss(\"heatmap\")\n</pre> miss_plot.visualize_miss(\"heatmap\") In\u00a0[11]: Copied! <pre>miss_plot.visualize_miss(visualization_type=\"histogram\", col_missing=col_1, num_bins=5)\n</pre> miss_plot.visualize_miss(visualization_type=\"histogram\", col_missing=col_1, num_bins=5) In\u00a0[12]: Copied! <pre>miss_plot.visualize_miss(visualization_type=\"boxplot\", col_missing=col_1)\n</pre> miss_plot.visualize_miss(visualization_type=\"boxplot\", col_missing=col_1) In\u00a0[13]: Copied! <pre>miss_plot.visualize_miss(visualization_type=\"scatterplot\", cols=(col_1, col_2))\n</pre> miss_plot.visualize_miss(visualization_type=\"scatterplot\", cols=(col_1, col_2)) <p>We can also change the axis of the plot (x or y for missing):</p> In\u00a0[14]: Copied! <pre>miss_plot.visualize_miss(visualization_type=\"scatterplot\", cols=(col_2, col_1))\n</pre> miss_plot.visualize_miss(visualization_type=\"scatterplot\", cols=(col_2, col_1)) In\u00a0[33]: Copied! <pre>_, iris_miss_2d = create_iris_missing(mr, col_1, col_2)\n</pre> _, iris_miss_2d = create_iris_missing(mr, col_1, col_2) In\u00a0[34]: Copied! <pre>iris_miss_2d\n</pre> iris_miss_2d Out[34]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 NaN 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 NaN 1.5 0.2 4 5.0 NaN 1.4 0.2 ... ... ... ... ... 145 6.7 NaN 5.2 2.3 146 6.3 2.5 NaN 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 NaN 2.3 149 5.9 NaN 5.1 1.8 <p>150 rows \u00d7 4 columns</p> In\u00a0[35]: Copied! <pre>miss_plot_2d = PlotMissingData(data_missing=iris_miss_2d, data_original=iris_df)\n</pre> miss_plot_2d = PlotMissingData(data_missing=iris_miss_2d, data_original=iris_df) In\u00a0[36]: Copied! <pre>miss_plot_2d.visualize_miss(\"normal\")\n</pre> miss_plot_2d.visualize_miss(\"normal\") In\u00a0[37]: Copied! <pre>miss_plot_2d.visualize_miss(\"bar\")\n</pre> miss_plot_2d.visualize_miss(\"bar\") In\u00a0[38]: Copied! <pre>miss_plot_2d.visualize_miss(\"dendrogram\")\n</pre> miss_plot_2d.visualize_miss(\"dendrogram\") In\u00a0[39]: Copied! <pre>miss_plot_2d.visualize_miss(\"heatmap\")\n</pre> miss_plot_2d.visualize_miss(\"heatmap\") In\u00a0[40]: Copied! <pre>miss_plot_2d.visualize_miss(visualization_type=\"histogram\", col_missing=col_1, num_bins=5)\n</pre> miss_plot_2d.visualize_miss(visualization_type=\"histogram\", col_missing=col_1, num_bins=5) In\u00a0[41]: Copied! <pre>miss_plot_2d.visualize_miss(visualization_type=\"histogram\", col_missing=col_2, num_bins=5)\n</pre> miss_plot_2d.visualize_miss(visualization_type=\"histogram\", col_missing=col_2, num_bins=5) In\u00a0[42]: Copied! <pre>miss_plot_2d.visualize_miss(visualization_type=\"boxplot\", col_missing=col_1)\n</pre> miss_plot_2d.visualize_miss(visualization_type=\"boxplot\", col_missing=col_1) In\u00a0[43]: Copied! <pre>miss_plot_2d.visualize_miss(visualization_type=\"boxplot\", col_missing=col_2)\n</pre> miss_plot_2d.visualize_miss(visualization_type=\"boxplot\", col_missing=col_2) In\u00a0[44]: Copied! <pre>miss_plot_2d.visualize_miss(visualization_type=\"scatterplot\", cols=(col_1, col_2))\n</pre> miss_plot_2d.visualize_miss(visualization_type=\"scatterplot\", cols=(col_1, col_2)) In\u00a0[201]: Copied! <pre>iris_miss\n</pre> iris_miss Out[201]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 NaN 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 NaN 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 ... ... ... ... ... 145 6.7 3.0 NaN 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 NaN 2.3 149 5.9 3.0 NaN 1.8 <p>150 rows \u00d7 4 columns</p>"},{"location":"examples_plots/#only-1-feature-with-missing-values","title":"Only 1 feature with missing values\u00b6","text":""},{"location":"examples_plots/#two-features-with-missing-values","title":"Two features with missing values\u00b6","text":""},{"location":"mar_univariate_example/","title":"MAR univariate example","text":"<p>A basic example of generate artificial missing data under Missing at Random (MAR) mechanism with mdatagen library with the Iris dataset from scikit-learn. The observed feature is \"petal length\" and the feature that will receive the missing values is \"petal width\". The simulated missing rate is 12%. The method to choose missing values is random.</p> In\u00a0[1]: Copied! <pre># Import the libraries\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom mdatagen.univariate.uMAR import uMAR\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target    # Label values\n\n# Create a instance with missing rate equal to 12% in dataset under MAR mechanism\ngenerator = uMAR(X=X, \n                 y=y, \n                 missing_rate=12, \n                 x_miss='petal width (cm)',\n                 x_obs='petal length (cm)')\n\n# Generate the missing data under MNAR mechanism\ngenerate_data = generator.random()\nprint(generate_data.isna().sum())\n</pre> # Import the libraries import pandas as pd from sklearn.datasets import load_iris from mdatagen.univariate.uMAR import uMAR  # Load the data iris = load_iris() iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  X = iris_df.copy()   # Features y = iris.target    # Label values  # Create a instance with missing rate equal to 12% in dataset under MAR mechanism generator = uMAR(X=X,                   y=y,                   missing_rate=12,                   x_miss='petal width (cm)',                  x_obs='petal length (cm)')  # Generate the missing data under MNAR mechanism generate_data = generator.random() print(generate_data.isna().sum()) <pre>sepal length (cm)     0\nsepal width (cm)      0\npetal length (cm)    38\npetal width (cm)      0\ntarget                0\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"mcar_univariate_example/","title":"MCAR univariate example","text":"<p>A basic example of generate artificial missing data with mdatagen library with the Iris dataset from scikit-learn. The feature petal length will receive the missing values under Missing Completly at Random (MCAR) mechanism. The simulated missing rate is 25%. The method to choose missing values is random.</p> In\u00a0[1]: Copied! <pre># Import the libraries\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom mdatagen.univariate.uMCAR import uMCAR\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target    # Label values\n\n# Create a instance with missing rate equal to 25% in dataset under MCAR mechanism\ngenerator = uMCAR(X=X, y=y, missing_rate=25, x_miss='petal length (cm)')\n\n# Generate the missing data under MNAR mechanism\ngenerate_data = generator.random()\nprint(generate_data.isna().sum())\n</pre> # Import the libraries import pandas as pd from sklearn.datasets import load_iris from mdatagen.univariate.uMCAR import uMCAR  # Load the data iris = load_iris() iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  X = iris_df.copy()   # Features y = iris.target    # Label values  # Create a instance with missing rate equal to 25% in dataset under MCAR mechanism generator = uMCAR(X=X, y=y, missing_rate=25, x_miss='petal length (cm)')  # Generate the missing data under MNAR mechanism generate_data = generator.random() print(generate_data.isna().sum()) <pre>sepal length (cm)     0\nsepal width (cm)      0\npetal length (cm)    38\npetal width (cm)      0\ntarget                0\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"mnar_multivariate_examples/","title":"MNAR Multivariate Examples","text":"In\u00a0[6]: Copied! <pre># Import the libraries\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\n\nfrom mdatagen.multivariate.mMNAR import mMNAR\n\n# Load the data\nwiscosin = load_breast_cancer()\nwiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names)\n\nX = wiscosin_df.copy()   # Features\ny = wiscosin.target    # Label values\n</pre> # Import the libraries import pandas as pd from sklearn.datasets import load_breast_cancer  from mdatagen.multivariate.mMNAR import mMNAR  # Load the data wiscosin = load_breast_cancer() wiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names)  X = wiscosin_df.copy()   # Features y = wiscosin.target    # Label values <ul> <li>Random</li> </ul> In\u00a0[\u00a0]: Copied! <pre># Create a instance for MNAR mechanism\ngenerator = mMNAR(X=X, \n                  y=y,\n                  n_xmiss = 8, # 8 feature that will receive the missingness randomly\n                  threshold = 1) # highest values\n\n# Generate the missing data under MNAR mechanism up to 20% missing rate\ngenerate_data = generator.random(missing_rate=20, \n                                 deterministic=True) # Missingness based on own values\n\nqtd_miss = sum(generate_data.isna().sum())\nprint(f\"Global Missing rate = {round(qtd_miss/(generate_data.shape[0]*generate_data.shape[1]),2)}\")\nprint(\"\\n\")\nprint(\"Columns that receive the missingness:\")\nfor col in generate_data.columns:\n    if generate_data[col].isna().sum() &gt; 0:\n        print(col)\n    else:\n        pass\n</pre> # Create a instance for MNAR mechanism generator = mMNAR(X=X,                    y=y,                   n_xmiss = 8, # 8 feature that will receive the missingness randomly                   threshold = 1) # highest values  # Generate the missing data under MNAR mechanism up to 20% missing rate generate_data = generator.random(missing_rate=20,                                   deterministic=True) # Missingness based on own values  qtd_miss = sum(generate_data.isna().sum()) print(f\"Global Missing rate = {round(qtd_miss/(generate_data.shape[0]*generate_data.shape[1]),2)}\") print(\"\\n\") print(\"Columns that receive the missingness:\") for col in generate_data.columns:     if generate_data[col].isna().sum() &gt; 0:         print(col)     else:         pass  <pre>Global Missing rate = 0.19\n\n\nColumns that receive the missingness:\nmean radius\nmean compactness\nmean symmetry\ntexture error\nworst texture\nworst smoothness\nworst concave points\nworst symmetry\n</pre> <ul> <li>Correlated</li> </ul> In\u00a0[8]: Copied! <pre># Create a instance for MNAR mechanism\ngenerator = mMNAR(X=X, \n                  y=y,\n                  threshold = 1) # highest values\n\n# Generate the missing data under MNAR mechanism up to 20% missing rate\ngenerate_data = generator.correlated(missing_rate=20, \n                                 deterministic=True) # Missingness based on own values\n\nqtd_miss = sum(generate_data.isna().sum())\nprint(f\"Global Missing rate = {round(qtd_miss/(generate_data.shape[0]*generate_data.shape[1]),2)}\")\nprint(\"\\n\")\nprint(\"Columns that receive the missingness:\")\nfor col in generate_data.columns:\n    if generate_data[col].isna().sum() &gt; 0:\n        print(col)\n    else:\n        pass\n</pre> # Create a instance for MNAR mechanism generator = mMNAR(X=X,                    y=y,                   threshold = 1) # highest values  # Generate the missing data under MNAR mechanism up to 20% missing rate generate_data = generator.correlated(missing_rate=20,                                   deterministic=True) # Missingness based on own values  qtd_miss = sum(generate_data.isna().sum()) print(f\"Global Missing rate = {round(qtd_miss/(generate_data.shape[0]*generate_data.shape[1]),2)}\") print(\"\\n\") print(\"Columns that receive the missingness:\") for col in generate_data.columns:     if generate_data[col].isna().sum() &gt; 0:         print(col)     else:         pass  <pre>Global Missing rate = 0.2\n\n\nColumns that receive the missingness:\nmean perimeter\nmean concave points\nradius error\narea error\nsmoothness error\ncompactness error\nconcave points error\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\n</pre> <ul> <li>Missigness Based on Own Values (MBOV) using a randomess to choose miss locations in each feature -&gt; MBOV_randomness</li> </ul> In\u00a0[9]: Copied! <pre># Create a instance for MNAR mechanism\ngenerator = mMNAR(X=X, \n                  y=y,\n                  ) \n\nlist_to_gen_miss = [\"mean radius\",\"texture error\", \"area error\"]\n\n# Generate the missing data under MNAR mechanism up to 20% missing rate\ngenerate_data = generator.MBOV_randomness(missing_rate=20, \n                                          columns=list_to_gen_miss,\n                                          randomness=0.3)\n\n                                        \nqtd_miss = sum(generate_data.isna().sum())\nprint(f\"Global Missing rate = {round(qtd_miss / (len(list_to_gen_miss) * generate_data.shape[0]),2)}\")\nprint(\"\\n\")\nprint(\"Columns that receive the missingness:\")\nfor col in generate_data.columns:\n    if generate_data[col].isna().sum() &gt; 0:\n        print(col)\n    else:\n        pass\n</pre> # Create a instance for MNAR mechanism generator = mMNAR(X=X,                    y=y,                   )   list_to_gen_miss = [\"mean radius\",\"texture error\", \"area error\"]  # Generate the missing data under MNAR mechanism up to 20% missing rate generate_data = generator.MBOV_randomness(missing_rate=20,                                            columns=list_to_gen_miss,                                           randomness=0.3)                                           qtd_miss = sum(generate_data.isna().sum()) print(f\"Global Missing rate = {round(qtd_miss / (len(list_to_gen_miss) * generate_data.shape[0]),2)}\") print(\"\\n\") print(\"Columns that receive the missingness:\") for col in generate_data.columns:     if generate_data[col].isna().sum() &gt; 0:         print(col)     else:         pass <pre>Global Missing rate = 0.19\n\n\nColumns that receive the missingness:\nmean radius\ntexture error\narea error\n</pre> <ul> <li>Missingness Based on Intra-Relation (MBIR)</li> </ul> In\u00a0[10]: Copied! <pre># Create a instance for MNAR mechanism\ngenerator = mMNAR(X=X, \n                  y=y,\n                  ) \n\nlist_to_gen_miss = [\"mean radius\",\"texture error\", \"area error\"]\n\n# Generate the missing data under MNAR mechanism up to 20% missing rate\ngenerate_data = generator.MBIR(missing_rate=20, \n                               columns=list_to_gen_miss,\n                               statistical_method=\"Mann-Whitney\")\n                   \nqtd_miss = sum(generate_data.isna().sum())\nprint(f\"Global Missing rate = {round(qtd_miss / (len(list_to_gen_miss) * generate_data.shape[0]),2)}\")\nprint(\"\\n\")\nprint(\"Columns that receive the missingness:\")\nfor col in generate_data.columns:\n    if generate_data[col].isna().sum() &gt; 0:\n        print(col)\n    else:\n        pass\n</pre> # Create a instance for MNAR mechanism generator = mMNAR(X=X,                    y=y,                   )   list_to_gen_miss = [\"mean radius\",\"texture error\", \"area error\"]  # Generate the missing data under MNAR mechanism up to 20% missing rate generate_data = generator.MBIR(missing_rate=20,                                 columns=list_to_gen_miss,                                statistical_method=\"Mann-Whitney\")                     qtd_miss = sum(generate_data.isna().sum()) print(f\"Global Missing rate = {round(qtd_miss / (len(list_to_gen_miss) * generate_data.shape[0]),2)}\") print(\"\\n\") print(\"Columns that receive the missingness:\") for col in generate_data.columns:     if generate_data[col].isna().sum() &gt; 0:         print(col)     else:         pass <pre>Global Missing rate = 0.2\n\n\nColumns that receive the missingness:\nmean radius\ntexture error\narea error\n</pre>"},{"location":"mnar_multivariate_examples/#mnar-mechanism","title":"MNAR mechanism\u00b6","text":"<p>This Jupyter Notebook provides various strategies to generate artificial missing data under MNAR mechanism in multivariate scenario. Our example is using the Breast Cancer Wiscosin dataset from Scikit-learn.</p> <p>The approaches covered in this Jupyter Notebook are:</p> <ul> <li>Random</li> <li>Correlated</li> <li>Missigness Based on Own Values (MBOV) using a randomess to choose miss locations in each feature</li> <li>Missingness Based on Intra-Relation (MBIR)</li> </ul>"},{"location":"mnar_univariate_example/","title":"MNAR univariate example","text":"<p>A basic example of generate artificial missing data with mdatagen library with the Iris dataset from scikit-learn. The most correlated feature with label will receive the missing values under Missing Not at Random (MNAR) mechanism. The simulated missing rate is 10% (default). The method to choose missing values is lowest.</p> In\u00a0[1]: Copied! <pre>import pandas as pd\nfrom sklearn.datasets import load_iris\n\nfrom mdatagen.univariate.uMNAR import uMNAR\n\n# Load the data\niris = load_iris()\niris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\nX = iris_df.copy()   # Features\ny = iris.target    # Label values\n\n# Create a instance with missing rate equal to 10% in dataset under MNAR mechanism\ngenerator = uMNAR(X=X, y=y, threshold=0)\n\n# Generate the missing data under MNAR mechanism\ngenerate_data = generator.run()\nprint(generate_data.isna().sum())\n</pre> import pandas as pd from sklearn.datasets import load_iris  from mdatagen.univariate.uMNAR import uMNAR  # Load the data iris = load_iris() iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  X = iris_df.copy()   # Features y = iris.target    # Label values  # Create a instance with missing rate equal to 10% in dataset under MNAR mechanism generator = uMNAR(X=X, y=y, threshold=0)  # Generate the missing data under MNAR mechanism generate_data = generator.run() print(generate_data.isna().sum()) <pre>sepal length (cm)     0\nsepal width (cm)      0\npetal length (cm)     0\npetal width (cm)     15\ntarget                0\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"multivariate/","title":"Documentation about Multivariate scenario","text":""},{"location":"multivariate/#documentation-about-multivariate-mechanisms","title":"Documentation about Multivariate mechanisms","text":"<p>missing-data-generator has a multivariate approach that refers to more than one feature in a dataset containing missing values. From this concept, the literature presents three mechanisms: Missing Completely at Random (MCAR), Missing Not at Random (MNAR), and Missing at Random (MAR). Each mechanism has different strategies for choosing the missing locations, which are implemented in this Python package. For all methods in multivariate, the missing data rate is calculated for the entire dataset. </p> <p>The strategies to generate artificial missing data are described as follows:</p>"},{"location":"multivariate/#missing-at-random-mar","title":"Missing at Random (MAR)","text":"<ul> <li> <p>random: This method generates artificial missing data in <code>n_xmiss</code> features, selected randomly. If <code>n_xmiss</code> is not specified, it defaults to two. However, an error may occur depending on the input dataset's length. Both the observed feature and <code>x_miss</code> are randomly chosen. The missing locations in <code>x_miss</code> are determined by the lower values in the observed feature for each corresponding <code>x_miss</code>.</p> </li> <li> <p>correlated: This method generates missing data in features from the dataset, excluding the class (target). The strategy involves creating pairs/triples of features based on their correlation. For each pair, the most correlated feature with the class becomes <code>x_miss</code>, while the remaining is the observed feature (<code>x_obs</code>) determining missing locations in <code>x_miss</code>. In the case of triples, the first and second features most correlated with the class are designated as <code>x_miss</code>, and the third is <code>x_obs</code>. The selection criterion involves choosing the lowest values from the observed feature. Given that only one feature in a pair experiences missing data, the missing rate is twice the input missing rate. For triples, it is 1.5 times the missing rate.</p> </li> <li> <p>median: This method generates artificial missing data in the dataset, excluding the class (target). The strategy entails creating pairs/triples of features based on their correlation. For each pair/triple, an observed feature (<code>x_obs</code>) is randomly selected. The median of x_obs establishes two groups\u2014those lower and those equal to or higher than the median. Subsequently, a group is randomly chosen, and the lowest values within it determine the missing locations in <code>x_miss</code>. It is essential to note that for triples, two features will be designated as <code>x_miss</code>. Like the correlated method, the missing rate is twice the input rate for pairs and 1.5 times for triples rate.</p> </li> </ul>"},{"location":"multivariate/#missing-not-at-random-mnar","title":"Missing Not at Random (MNAR)","text":"<ul> <li> <p>random: Method to randomly choose the n_xmiss features x_miss in the dataset to generate missing data. The missing locations in x_miss are determined by the lower values based on an unobserved or feature itself.</p> </li> <li> <p>correlated: The correlated method mirrors the approach used in the Correlated Method of the Missing at Random (MAR). However, in the case of Missing Not at Random (MNAR), this technique diverges by avoiding using observed features from the dataset. Instead, MNAR employs an unobserved random feature that is not present in the dataset or uses the feature values itself.</p> </li> <li> <p>median: The median method shares similarities with the Median Method in the Missing at Random (MAR). However, in the case of Missing Not at Random (MNAR), this technique diverges by avoiding using observed features from the dataset. Instead, MNAR employs an unobserved random feature that is not present in the dataset or uses the feature values itself.</p> </li> <li> <p>MBOUV: Method to generate missing data based on the Missingness Based on Own and Unobserved Values (MBOUV), and it is described as follows: MBUV is applied to all nominal features and half of the continuous ones, while MBOV (with lower values removal) is applied to the remaining half of the features. Both approaches are applied iteratively, and the split of continuous features is performed randomly.</p> </li> <li> <p>MBOV_randomness: Method to generate missing data based on Missingness Based on Own Values (MBOV) using randomness to choose missing locations in each input feature. Randomness is a float between 0 and 0.5, introducing stochasticity to generate the missing locations in x_miss. If randomness equals 0, only the lowest values will be selected.</p> </li> <li> <p>MBOV_median: Method to generate missing data based on Missingness Based on Own Values (MBOV) using the median to choose missing locations in each input feature. For this method, object types are not allowed. The missing locations are closer to the median of each feature. We utilize np.argsort of the difference between the current value and the median of the feature. The N lowest values are selected to be missing.</p> </li> <li> <p>MBIR: Method to generate missing data based on Missingness Based on Intra-Relation (MBIR). MBIR is a novel approach to generating missing data by the MNAR mechanism. This method is based on the MAR strategy and involves finding the lowest values from an observed feature x_obs. Then, x_miss receives the missing values, and an auxiliary indicator is created, which is 1 for missing and 0 otherwise. The user can select the statistical method to evaluate if evidence of a significant difference exists. Finally, the feature with the most statistically significant differences is selected to determine the missing locations, and after that, it is removed from the dataset. This feature is dropped because MNAR uses an unobserved feature from the dataset. It is essential to clarify that if the user inputs all columns in the dataset, the entire dataset will be dropped.</p> </li> </ul>"},{"location":"multivariate/#missing-completly-at-random-mcar","title":"Missing Completly at Random (MCAR)","text":"<ul> <li> <p>random: Method to generate missing data in all datasets randomly. </p> </li> <li> <p>binomial: Function to generate missing data in input columns by Bernoulli distribution for each attribute informed. It is important to clarify that, similar to univariate MCAR binomial, occasionally, this method may only partially generate the missing rate specified by the user.</p> </li> </ul>"},{"location":"novel_mnar_multivariate_example/","title":"Novel MNAR Multivariate mechanism","text":"<p>A novel example of generate artificial missing data with mdatagen library with the Breast Cancer Wiscosin dataset from scikit-learn. The features will receive the missing values under Missing Not at Random (MNAR) mechanism. The simulated missing rate is 20%. The method to choose missing values is Missingness Based on Own and Unobserved Values (MBOUV).</p> In\u00a0[1]: Copied! <pre># Import the libraries\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\n\nfrom mdatagen.multivariate.mMNAR import mMNAR\n\n# Load the data\nwiscosin = load_breast_cancer()\nwiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names)\n\nX = wiscosin_df.copy()   # Features\ny = wiscosin.target    # Label values\n\n# Create a instance with missing rate equal to 20% in dataset under MNAR mechanism\ngenerator = mMNAR(X=X, y=y)\n\n# Generate the missing data under MNAR mechanism\ngenerate_data = generator.MBOUV(missing_rate=20, depend_on_external=X.columns)\nprint(generate_data.isna().sum())\n</pre> # Import the libraries import pandas as pd from sklearn.datasets import load_breast_cancer  from mdatagen.multivariate.mMNAR import mMNAR  # Load the data wiscosin = load_breast_cancer() wiscosin_df = pd.DataFrame(data=wiscosin.data, columns=wiscosin.feature_names)  X = wiscosin_df.copy()   # Features y = wiscosin.target    # Label values  # Create a instance with missing rate equal to 20% in dataset under MNAR mechanism generator = mMNAR(X=X, y=y)  # Generate the missing data under MNAR mechanism generate_data = generator.MBOUV(missing_rate=20, depend_on_external=X.columns) print(generate_data.isna().sum()) <pre>mean radius                166\nmean texture                61\nmean perimeter              35\nmean area                  148\nmean smoothness            156\nmean compactness           161\nmean concavity             112\nmean concave points        171\nmean symmetry               93\nmean fractal dimension     110\nradius error                74\ntexture error              160\nperimeter error             82\narea error                  63\nsmoothness error           160\ncompactness error          152\nconcavity error             99\nconcave points error       143\nsymmetry error             171\nfractal dimension error      1\nworst radius               170\nworst texture              159\nworst perimeter              4\nworst area                 170\nworst smoothness            51\nworst compactness          148\nworst concavity             42\nworst concave points       126\nworst symmetry              78\nworst fractal dimension    148\ntarget                       0\ndtype: int64\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"pattern_mar/","title":"Pattern mar","text":"<p>This notebook demonstrates how to generate missing data using the pattern-based multivariate amputation module available in the mdatagen package. This module is a wrapper around the pyampute package and addresses key challenges in generating artificial missing data under the MAR (Missing At Random) mechanism.</p> <p>In addition, an excellent video lesson is available on YouTube at the following link: \ud83d\udcfa https://youtu.be/jMEzKFV-ilc?si=bVQ-kYjOelAqdN0h</p> <p>van Buuren, S., J. P. L. Brand, C. G. M. Groothuis-Oudshoorn, and D. B. Rubin. Fully conditional specification in multivariate imputation. Journal of Statistical Computation and Simulation, 76(12):1049\u20131064, 2006.</p> <p>Schouten, R. M., P. Lugtig, and G. Vink. Generating missing values for simulation purposes: a multivariate amputation procedure. Journal of Statistical Computation and Simulation, 88(15):2909\u20132930, 2018.</p> In\u00a0[\u00a0]: Copied! <pre># Import the libraries\nimport numpy as np \nimport pmlb\nfrom mdatagen.multivariate.mMAR import mMAR\nfrom mdatagen.plots import PlotMissingData\n\n# Function to help split data\ndef split_data(data):\n    df = data.copy()\n    X = df.drop(columns=[\"target\"])\n    y = data[\"target\"]\n\n    return X,np.array(y)\n\n# The data from PMLB\nkddcup = pmlb.fetch_data('kddcup')\nX_, y_ = split_data(kddcup)\n\ngenerator = mMAR(X=X_, y=y_,n_Threads=1)\n\ngen_md = generator.pattern_missingness()\n</pre> # Import the libraries import numpy as np  import pmlb from mdatagen.multivariate.mMAR import mMAR from mdatagen.plots import PlotMissingData  # Function to help split data def split_data(data):     df = data.copy()     X = df.drop(columns=[\"target\"])     y = data[\"target\"]      return X,np.array(y)  # The data from PMLB kddcup = pmlb.fetch_data('kddcup') X_, y_ = split_data(kddcup)  generator = mMAR(X=X_, y=y_,n_Threads=1)  gen_md = generator.pattern_missingness() In\u00a0[4]: Copied! <pre>miss_plot = PlotMissingData(data_missing=gen_md, \n                            data_original=X_)\n\nmiss_plot.visualize_miss(\"normal\", save=False)\n</pre> miss_plot = PlotMissingData(data_missing=gen_md,                              data_original=X_)  miss_plot.visualize_miss(\"normal\", save=False) <ul> <li>A more robust example:</li> </ul> In\u00a0[7]: Copied! <pre>import pandas as pd\nseed = 2022\nrng = np.random.default_rng(seed)\n\nm = 1000\nn = 3\nX_compl = pd.DataFrame(rng.standard_normal((m, n)))\ny_compl = np.random.randint(0, 2, size=m)\n\npatterns = [{\n      \"score_to_probability_func\": \"SIGMOID-LEFT\",\n      \"mechanism\": \"MAR\",\n      \"incomplete_vars\":[1],\n      \"weights\": [2.3, 0, -0.4],\n      \"freq\": 0.7\n  },\n           {\n\n      \"mechanism\": \"MAR\",\n      \"incomplete_vars\":[2],\n      \"weights\": [0, 0, 1.3],\n      \"freq\": 0.3\n  }, ]\n\ngenerator = mMAR(X=X_compl, y=y_compl)\n\ngen_md = generator.pattern_missingness(patterns=patterns,\n                                       verbose=True)\n</pre> import pandas as pd seed = 2022 rng = np.random.default_rng(seed)  m = 1000 n = 3 X_compl = pd.DataFrame(rng.standard_normal((m, n))) y_compl = np.random.randint(0, 2, size=m)  patterns = [{       \"score_to_probability_func\": \"SIGMOID-LEFT\",       \"mechanism\": \"MAR\",       \"incomplete_vars\":[1],       \"weights\": [2.3, 0, -0.4],       \"freq\": 0.7   },            {        \"mechanism\": \"MAR\",       \"incomplete_vars\":[2],       \"weights\": [0, 0, 1.3],       \"freq\": 0.3   }, ]  generator = mMAR(X=X_compl, y=y_compl)  gen_md = generator.pattern_missingness(patterns=patterns,                                        verbose=True) In\u00a0[8]: Copied! <pre>miss_plot = PlotMissingData(data_missing=gen_md, \n                            data_original=X_compl)\n\nmiss_plot.visualize_miss(\"bar\", save=False)\n</pre> miss_plot = PlotMissingData(data_missing=gen_md,                              data_original=X_compl)  miss_plot.visualize_miss(\"bar\", save=False) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"scalability_test/","title":"Scalability test","text":"<p>This Jupyter Notebook provides examples of how to apply the mdatagen library to large datasets. Here, we used the 'Penn Machine Learning Benchmarks' to fetch the data. We selected small, medium, and large datasets, as described in the table below:</p> Dataset n_instances n_features n_binary_features n_categorical_features n_continuos_features mushroom 8124 22 5 16 1 adult 48842 14 1 4 9 kddcup 494020 41 4 9 28 poker 1025010 10 0 5 5 mfeat_pixel 2000 240 0 240 0 <p>We selected the MAR multivariate mechanism under median strategy because it represents the worst-case scenario for larger datasets. Moreover, we provided an example to set the number of Threads to parallelize the generation.</p> In\u00a0[1]: Copied! <pre># Import the libraries\nimport numpy as np \nimport pmlb\nfrom mdatagen.multivariate.mMAR import mMAR\nfrom time import perf_counter\n</pre> # Import the libraries import numpy as np  import pmlb from mdatagen.multivariate.mMAR import mMAR from time import perf_counter In\u00a0[2]: Copied! <pre># Function to help split data\ndef split_data(data):\n    df = data.copy()\n    X = df.drop(columns=[\"target\"])\n    y = data[\"target\"]\n\n    return X,np.array(y)\n\n# The data from PMLB\nadult_data = pmlb.fetch_data('adult')\nkddcup = pmlb.fetch_data('kddcup')\nmushroom = pmlb.fetch_data('mushroom')\nmfeat_pixel = pmlb.fetch_data('mfeat_pixel')\npoker  = pmlb.fetch_data('poker')\n</pre> # Function to help split data def split_data(data):     df = data.copy()     X = df.drop(columns=[\"target\"])     y = data[\"target\"]      return X,np.array(y)  # The data from PMLB adult_data = pmlb.fetch_data('adult') kddcup = pmlb.fetch_data('kddcup') mushroom = pmlb.fetch_data('mushroom') mfeat_pixel = pmlb.fetch_data('mfeat_pixel') poker  = pmlb.fetch_data('poker') In\u00a0[14]: Copied! <pre>import os\nX_, y_ = split_data(mushroom)\n\ntime_init = perf_counter()\ngenerator = mMAR(X=X_, y=y_, n_Threads=4)\ngen_md = generator.median(missing_rate=20)\n\ntime_end = perf_counter()\nprint(f\"Tempo: {round(time_end-time_init,4)} s \")\n</pre> import os X_, y_ = split_data(mushroom)  time_init = perf_counter() generator = mMAR(X=X_, y=y_, n_Threads=4) gen_md = generator.median(missing_rate=20)  time_end = perf_counter() print(f\"Tempo: {round(time_end-time_init,4)} s \") <pre>Tempo: 1.7455 s \n</pre>"},{"location":"univariate/","title":"Documentation about Univariate scenario","text":""},{"location":"univariate/#documentation-about-univariate-mechanisms","title":"Documentation about Univariate mechanisms","text":"<p>missing-data-generator has a univariate approach that refers to only one feature in the dataset containing missing values. From this concept, the literature presents three mechanisms: Missing Completely at Random (MCAR), Missing Not at Random (MNAR), and Missing at Random (MAR). Each mechanism has different strategies for choosing the missing locations, which are implemented in this Python package.</p> <p>The strategies to generate artificial missing data are described as follows:</p>"},{"location":"univariate/#missng-at-random-mar","title":"Missng At Random (MAR)","text":"<ul> <li> <p>lowest: Method to generate missing values in the feature <code>x_miss</code> by selecting the lowest values from an observed feature based on a specified missing rate;</p> </li> <li> <p>rank: A rank is created for the observed feature; this rank serves as the criterion for identifying the missing locations in the feature <code>x_miss</code>. While the original paper proposed a rank determined by the sum of all ranks, in the mdatagen package, we employ the maximum rank plus 1 to determine whether the index will be missing. New random numbers are generated to facilitate continued searching if the target missing rate is not achieved after 50 iterations.</p> </li> <li> <p>median: This function generates missing data in the feature <code>x_miss</code> by utilizing the median of an observed feature <code>x_obs</code>. The median of <code>x_obs</code> results in two groups\u2014those equal to or higher than the median and those lower than the median. The group with values higher or equal to the median is chosen with a nine times greater probability based on a specified missing rate.</p> </li> <li> <p>highest: This function generates missing values in the feature <code>x_miss</code> by selecting the highest values from an observed feature.</p> </li> <li> <p>mix: This function generates missing values in the feature <code>x_miss</code> by incorporating the N/2 lowest values and N/2 highest values from an observed feature, where N is the missing data rate multiplied by the patterns from the dataset.</p> </li> </ul>"},{"location":"univariate/#missing-not-at-random-mnar","title":"Missing Not at Random (MNAR)","text":"<ul> <li>run: Method to generate missing values in the feature <code>x_miss</code> by selecting the threshold to choose values from an unobserved feature or feature itself. The threshold is a float between 0 and 1. If the threshold equals 0, the lowest values from an unobserved/observed feature will be selected to determine the missing locations in <code>x_miss</code>. Otherwise, if the threshold is 1, the highest values will be selected. This strategy is a generic implementation in the literature, and the user can employ various methodologies. The unobserved feature is not in the dataset; it consists of a range of random numbers with the same length as the patterns.</li> </ul>"},{"location":"univariate/#missing-completly-at-random-mcar","title":"Missing Completly at Random (MCAR)","text":"<ul> <li> <p>random: Method to randomly select missing locations in the feature <code>x_miss</code>.</p> </li> <li> <p>binomial: Method to determine feature <code>x_miss</code> locations to be missing using a Bernoulli distribution. In this method, we implement the Bernoulli distribution using <code>numpy.binomial</code>; occasionally, this method may not precisely generate the missing rate specified by the user.</p> </li> </ul>"},{"location":"api-docs/MAR_multivariate/","title":"MAR multivariate: mMAR Class","text":""},{"location":"api-docs/MAR_multivariate/#mdatagen.multivariate.mMAR","title":"mMAR","text":""},{"location":"api-docs/MAR_multivariate/#mdatagen.multivariate.mMAR.mMAR","title":"mMAR","text":"<pre><code>mMAR(X: DataFrame, y: ndarray, n_xmiss: int = 2, missTarget: bool = False, n_Threads: int = 1)\n</code></pre> <p>A class to generate missing data in a dataset based on the Missing At Random (MAR) mechanism for multiple features simultaneously.</p> <p>Args:     X (pd.DataFrame): The dataset to receive the missing data.     y (np.array): The label values from dataset     n_xmiss (int): The number of features in the dataset that will receive missing values. Default is 2.     missTarget (bool, optional): A flag to generate missing into the target.</p> <p>Example Usage:</p> <pre><code># Create an instance of the MAR class\ngenerator = MAR(X, y, n_xmiss=4)\n\n# Generate missing values using the random strategy\ndata_md = generator.random(missing_rate = 20)\n</code></pre>"},{"location":"api-docs/MAR_multivariate/#mdatagen.multivariate.mMAR.mMAR.random","title":"random","text":"<pre><code>random(missing_rate: int = 10) -&gt; pd.DataFrame\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MAR_multivariate/#mdatagen.multivariate.mMAR.mMAR.correlated","title":"correlated","text":"<pre><code>correlated(missing_rate: int = 10) -&gt; pd.DataFrame\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MAR_multivariate/#mdatagen.multivariate.mMAR.mMAR.median","title":"median","text":"<pre><code>median(missing_rate: int = 10) -&gt; pd.DataFrame\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MAR_multivariate/#mdatagen.multivariate.mMAR.mMAR.pattern_missingness","title":"pattern_missingness","text":"<pre><code>pattern_missingness(patterns: List[Dict] = None, missing_rate: int = 10, std: bool = True, verbose: bool = False, seed: Optional[int] = None, lower_range: float = -3, upper_range: float = 3, max_diff_with_target: float = 0.001, max_iter: int = 100)\n</code></pre> <p>Generate missing data using pattern-based multivariate amputation.</p> <p>References: [2] van Buuren, S., J. P. L. Brand, C. G. M. Groothuis-Oudshoorn, and D. B. Rubin. Fully conditional specification in multivariate imputation. Journal of Statistical Computation and Simulation, 76(12):1049\u20131064, 2006.</p> <p>[3] Schouten, R. M., P. Lugtig, and G. Vink. Generating missing values for simulation purposes: a multivariate amputation procedure. Journal of Statistical Computation and Simulation, 88(15):2909\u20132930, 2018.</p>"},{"location":"api-docs/MAR_univariate/","title":"MAR univariate: uMAR Class","text":""},{"location":"api-docs/MAR_univariate/#mdatagen.univariate.uMAR","title":"uMAR","text":""},{"location":"api-docs/MAR_univariate/#mdatagen.univariate.uMAR.uMAR","title":"uMAR","text":"<pre><code>uMAR(X: DataFrame, y: ndarray, missing_rate: int = 10, x_miss: str = None, x_obs: str = None)\n</code></pre> <p>A class to generate missing values in a dataset based on the Missing At Random (MAR) univariate mechanism.</p> <p>Args:     X (pd.DataFrame): The dataset to receive the missing data.     y (np.array): The label values from dataset     missing_rate (int, optional): The rate of missing data to be generated. Default is 10.     x_miss (string): The name of feature to insert the missing data. If not informed, x_miss will be the feature most correlated with target     x_obs (string): The name of observed feature. If not informed, x_obs will be the feature most correlated with x_miss. Example Usage: <pre><code># Create an instance of the MAR class\ngenerator = MAR(X, y, missing_rate=20, x_miss='feature1')\n\n# Generate missing values using the lowest strategy\ndata_md = generator.lowest()\n</code></pre></p>"},{"location":"api-docs/MAR_univariate/#mdatagen.univariate.uMAR.uMAR.lowest","title":"lowest","text":"<pre><code>lowest()\n</code></pre> <p>Function to generate missing values in the feature (x_miss) using the lowest values from an observed feature.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MAR_univariate/#mdatagen.univariate.uMAR.uMAR.rank","title":"rank","text":"<pre><code>rank()\n</code></pre> <p>Function to generate missing values in the feature (x_miss) using a rank from an observed feature.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MAR_univariate/#mdatagen.univariate.uMAR.uMAR.median","title":"median","text":"<pre><code>median()\n</code></pre> <p>Function to generate missing data in the feature (x_miss) using the median of an observed feature.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MAR_univariate/#mdatagen.univariate.uMAR.uMAR.highest","title":"highest","text":"<pre><code>highest()\n</code></pre> <p>Function to generate missing values in the feature (x_miss) using the highest values from an observed feature.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MAR_univariate/#mdatagen.univariate.uMAR.uMAR.mix","title":"mix","text":"<pre><code>mix()\n</code></pre> <p>Function to generate missing values in the feature (x_miss) using the N/2 lowest values and N/2 highest values from an observed feature.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MCAR_multivariate/","title":"MCAR multivariate: mMCAR Class","text":""},{"location":"api-docs/MCAR_multivariate/#mdatagen.multivariate.mMCAR","title":"mMCAR","text":""},{"location":"api-docs/MCAR_multivariate/#mdatagen.multivariate.mMCAR.mMCAR","title":"mMCAR","text":"<pre><code>mMCAR(X: DataFrame, y: ndarray, missing_rate: int = 10, missTarget: bool = False, seed: int = None)\n</code></pre> <p>A class to generate missing data in a dataset based on the Missing Completely At Random (MCAR) mechanism for multiple features simultaneously.</p> <p>Args:     X (pd.DataFrame): The dataset to receive the missing data.     y (np.array): The label values from dataset     missing_rate (int, optional): The rate of missing data to be generated. Default is 10.     missTarget (bool, optional): A flag to generate missing into the target.     seed (int, optional): The seed for the random number generator.</p> <p>Example Usage: <pre><code># Create an instance of the MCAR class\ngenerator = MCAR(X, y, missing_rate=20)\n\n# Generate missing values using the random strategy\ndata_md = generator.random()\n</code></pre></p>"},{"location":"api-docs/MCAR_multivariate/#mdatagen.multivariate.mMCAR.mMCAR.random","title":"random","text":"<pre><code>random() -&gt; pd.DataFrame\n</code></pre> <p>Function to randomly generate missing data in all dataset.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MCAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MCAR_multivariate/#mdatagen.multivariate.mMCAR.mMCAR.binomial","title":"binomial","text":"<pre><code>binomial(columns: list = None)\n</code></pre> <p>Function to generate missing data in columns by Bernoulli distribution for each attribute informed.</p> <p>Args:     columns (list): A list of strings containing columns names.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MCAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MCAR_univariate/","title":"MCAR univariate: uMCAR Class","text":""},{"location":"api-docs/MCAR_univariate/#mdatagen.univariate.uMCAR","title":"uMCAR","text":""},{"location":"api-docs/MCAR_univariate/#mdatagen.univariate.uMCAR.uMCAR","title":"uMCAR","text":"<pre><code>uMCAR(X: DataFrame, y: ndarray, missing_rate: int = 10, x_miss: str = None, method: str = 'random', seed: int = None)\n</code></pre> <p>A class to generate missing values in a dataset based on the Missing Completely At Random (MCAR) univariate mechanism.</p> <p>Args:     X (pd.DataFrame): The dataset to receive the missing data.     y (np.array): The label values from dataset     missing_rate (int, optional): The rate of missing data to be generated. Default is 10.     x_miss (string, optional): The name of feature to insert the missing data.     method (str, optional): The method to choose x_miss. If x_miss not informed by user, x_miss will be choose randomly. The options to choose xmiss is [\"random\", \"correlated\", \"min\", \"max\"]. Default is \"random\"     seed (int, optional): The seed for the random number generator.</p> <p>Example Usage: <pre><code># Create an instance of the MCAR class\ngenerator = MCAR(X, y, missing_rate=20, method=\"correlated\")\n\n# Generate missing values using the random strategy\ndata_md = generator.random()\n</code></pre></p>"},{"location":"api-docs/MCAR_univariate/#mdatagen.univariate.uMCAR.uMCAR.random","title":"random","text":"<pre><code>random()\n</code></pre> <p>Function to randomly select locations in the feature (x_miss) to be missing.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MCAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MCAR_univariate/#mdatagen.univariate.uMCAR.uMCAR.binomial","title":"binomial","text":"<pre><code>binomial()\n</code></pre> <p>Function to choose the feature (x_miss) locations to be missing by Bernoulli distribution.</p> <p>Returns:     dataset (DataFrame): The dataset with missing values generated under     the MCAR mechanism.</p> <p>Reference: [1] Santos, M. S., R. C. Pereira, A. F. Costa, J. P. Soares, J. Santos, and P. H. Abreu. 2019. Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access 7: 11651\u201367.</p>"},{"location":"api-docs/MNAR_multivariate/","title":"MNAR multivariate: uMNAR Class","text":""},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR","title":"mMNAR","text":""},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR","title":"mMNAR","text":"<pre><code>mMNAR(X: DataFrame, y: ndarray, threshold: float = 0, n_xmiss: int = 2, missTarget: bool = False, n_Threads: int = 1)\n</code></pre> <p>A class to generate missing values in a dataset based on the Missing Not At Random (MNAR) mechanism for multiple features simultaneously.</p> <p>Args:     X (pd.DataFrame): The dataset to receive the missing data.     y (np.array): The label values from dataset     missing_rate (int, optional): The rate of missing data to be generated. Default is 10.</p> <p>Keyword Args:     n_xmiss (int, optional): The number of features in the dataset that will receive missing values. Default is the number of features in dataset.     threshold (float, optional): The threshold to select the locations in feature (xmiss) to receive missing values where 0 indicates de lowest and 1 highest values. Default is 0     missTarget (bool, optional): A flag to generate missing into the target.</p> <p>Example Usage: <pre><code># Create an instance of the MNAR class\ngenerator = MNAR(X, y)\n\n# Generate missing values using the random strategy\ndata_md = generator.random()\n</code></pre></p>"},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR.random","title":"random","text":"<pre><code>random(missing_rate: int = 10, deterministic: bool = True)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR.correlated","title":"correlated","text":"<pre><code>correlated(missing_rate: int = 10, deterministic: bool = False)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR.median","title":"median","text":"<pre><code>median(missing_rate: int = 10, deterministic: bool = False)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR.MBOUV","title":"MBOUV","text":"<pre><code>MBOUV(missing_rate: int = 10, depend_on_external=None, ascending=True)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR.MBOV_randomness","title":"MBOV_randomness","text":"<pre><code>MBOV_randomness(missing_rate: int = 10, randomness: float = 0, columns: list = None)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR.MBOV_median","title":"MBOV_median","text":"<pre><code>MBOV_median(missing_rate: int = 10, columns: list = None)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_multivariate/#mdatagen.multivariate.mMNAR.mMNAR.MBIR","title":"MBIR","text":"<pre><code>MBIR(missing_rate: int = 10, columns: list = None, statistical_method: str = 'Mann-Whitney')\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_univariate/","title":"MNAR multivariate: mMNAR Class","text":""},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR","title":"mMNAR","text":""},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR","title":"mMNAR","text":"<pre><code>mMNAR(X: DataFrame, y: ndarray, threshold: float = 0, n_xmiss: int = 2, missTarget: bool = False, n_Threads: int = 1)\n</code></pre> <p>A class to generate missing values in a dataset based on the Missing Not At Random (MNAR) mechanism for multiple features simultaneously.</p> <p>Args:     X (pd.DataFrame): The dataset to receive the missing data.     y (np.array): The label values from dataset     missing_rate (int, optional): The rate of missing data to be generated. Default is 10.</p> <p>Keyword Args:     n_xmiss (int, optional): The number of features in the dataset that will receive missing values. Default is the number of features in dataset.     threshold (float, optional): The threshold to select the locations in feature (xmiss) to receive missing values where 0 indicates de lowest and 1 highest values. Default is 0     missTarget (bool, optional): A flag to generate missing into the target.</p> <p>Example Usage: <pre><code># Create an instance of the MNAR class\ngenerator = MNAR(X, y)\n\n# Generate missing values using the random strategy\ndata_md = generator.random()\n</code></pre></p>"},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR.random","title":"random","text":"<pre><code>random(missing_rate: int = 10, deterministic: bool = True)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR.correlated","title":"correlated","text":"<pre><code>correlated(missing_rate: int = 10, deterministic: bool = False)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR.median","title":"median","text":"<pre><code>median(missing_rate: int = 10, deterministic: bool = False)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR.MBOUV","title":"MBOUV","text":"<pre><code>MBOUV(missing_rate: int = 10, depend_on_external=None, ascending=True)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR.MBOV_randomness","title":"MBOV_randomness","text":"<pre><code>MBOV_randomness(missing_rate: int = 10, randomness: float = 0, columns: list = None)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR.MBOV_median","title":"MBOV_median","text":"<pre><code>MBOV_median(missing_rate: int = 10, columns: list = None)\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/MNAR_univariate/#mdatagen.multivariate.mMNAR.mMNAR.MBIR","title":"MBIR","text":"<pre><code>MBIR(missing_rate: int = 10, columns: list = None, statistical_method: str = 'Mann-Whitney')\n</code></pre> <p>Generate missing data using parallel processing.</p>"},{"location":"api-docs/metrics/","title":"EvaluationImputation Class","text":""},{"location":"api-docs/plots/","title":"PlotMissingData Class","text":""}]}